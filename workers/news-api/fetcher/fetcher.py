#!/usr/bin/env python3
"""
RSS æ–°é—»æŠ“å–è„šæœ¬
åŠŸèƒ½: ä»å¤šä¸ª RSS æºæŠ“å–æ–°é—»ï¼Œä½¿ç”¨ AI ä¼˜åŒ–æ‘˜è¦ï¼Œä¸Šä¼ åˆ° Cloudflare Worker
"""

import os
import sys
import time
import re
import feedparser
import requests

# ============================================
# é…ç½®åŒºåŸŸ
# ============================================

# Worker API åœ°å€ (ä»ç¯å¢ƒå˜é‡è¯»å–)
API_URL = os.getenv("NEWS_API_URL") or os.getenv("API_URL", "https://news-api.zhusen-wang.workers.dev/add")

# API å¯†é’¥ (ä»ç¯å¢ƒå˜é‡è¯»å–)
API_KEY = os.getenv("NEWS_API_KEY") or os.getenv("API_KEY", "56299bfa63f7cacc3d3b59a6084ccd095d7d5858c3216c5b109618c2f07b5da2")

# Groq API Key (ä»ç¯å¢ƒå˜é‡è¯»å–)
# è·å–æ–¹å¼: https://console.groq.com/keys
GROQ_API_KEY = os.getenv("GROQ_API_KEY", "")

# æ˜¯å¦å¯ç”¨ AI æ‘˜è¦ (è®¾ä¸º "true" æˆ– "1" å¯ç”¨ï¼Œå…¶ä»–å€¼ç¦ç”¨)
ENABLE_AI_SUMMARY = os.getenv("ENABLE_AI_SUMMARY", "true").lower() in ("true", "1")

# RSS æºåˆ—è¡¨ (å¯ä»¥éšæ„æ·»åŠ )
SOURCES = [
    {
        "name": "Hacker News",
        "url": "https://news.ycombinator.com/rss"
    },
    {
        "name": "V2EX",
        "url": "https://www.v2ex.com/index.xml"
    },
    {
        "name": "36æ°ª",
        "url": "https://36kr.com/feed"
    },
    {
        "name": "å°‘æ•°æ´¾",
        "url": "https://sspai.com/feed"
    },
    {
        "name": "TechCrunch",
        "url": "https://techcrunch.com/feed/"
    },
    {
        "name": "The Verge",
        "url": "https://www.theverge.com/rss/index.xml"
    },
]

# è¯·æ±‚è¶…æ—¶æ—¶é—´ (ç§’)
REQUEST_TIMEOUT = 30

# ============================================
# AI æ‘˜è¦åŠŸèƒ½
# ============================================

def summarize_with_ai(title: str, raw_summary: str) -> str:
    """
    ä½¿ç”¨ Groq API (Llama 3) ä¼˜åŒ–æ–°é—»æ‘˜è¦

    Args:
        title: æ–°é—»æ ‡é¢˜
        raw_summary: åŸå§‹æ‘˜è¦

    Returns:
        AI ä¼˜åŒ–åçš„æ‘˜è¦ï¼Œå¤±è´¥æ—¶è¿”å›åŸå§‹æ‘˜è¦
    """
    if not GROQ_API_KEY:
        return raw_summary

    try:
        from groq import Groq

        client = Groq(api_key=GROQ_API_KEY)

        # æ¸…ç†åŸå§‹æ‘˜è¦ï¼Œå»é™¤ HTML æ ‡ç­¾å’Œè¿‡é•¿å†…å®¹
        clean_summary = raw_summary
        if "<" in clean_summary:
            clean_summary = re.sub(r'<[^>]+>', '', clean_summary)
        clean_summary = clean_summary.strip()[:1000]  # é™åˆ¶è¾“å…¥é•¿åº¦

        # æ„å»ºæç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªç§‘æŠ€æ–°é—»ç¼–è¾‘ã€‚è¯·é˜…è¯»ä»¥ä¸‹æ–°é—»æ ‡é¢˜å’ŒåŸå§‹æ‘˜è¦ï¼Œç”¨**ä¸­æ–‡**å†™ä¸€æ®µç®€çŸ­çš„æ€»ç»“ï¼ˆä¸è¶…è¿‡ 100 å­—ï¼‰ã€‚
å»é™¤éæ ¸å¿ƒä¿¡æ¯ï¼Œç›´å‡»è¦ç‚¹ã€‚å¦‚æœåŸå§‹å†…å®¹å·²ç»æ˜¯ä¸­æ–‡ï¼Œåˆ™ä¼˜åŒ–å…¶è¡¨è¾¾ã€‚

æ ‡é¢˜ï¼š{title}

æ‘˜è¦ï¼š{clean_summary}

è¯·ç›´æ¥è¾“å‡ºä¼˜åŒ–åçš„æ‘˜è¦ï¼Œä¸è¦åŠ ä»»ä½•å‰ç¼€æˆ–è§£é‡Šã€‚"""

        response = client.chat.completions.create(
            model="llama-3.3-8b-instant",  # æˆ– "llama3-8b-8192"
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=200,
        )

        ai_summary = response.choices[0].message.content.strip()

        # å¦‚æœ AI è¿”å›ä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹æ‘˜è¦
        if ai_summary:
            return ai_summary
        return raw_summary

    except ImportError:
        print("   âš ï¸  groq åº“æœªå®‰è£…ï¼Œä½¿ç”¨åŸå§‹æ‘˜è¦")
        return raw_summary
    except Exception as e:
        print(f"   âš ï¸  AI æ‘˜è¦å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ‘˜è¦")
        return raw_summary


# ============================================
# ä»¥ä¸‹ä»£ç æ— éœ€ä¿®æ”¹
# ============================================


def clean_html(text: str) -> str:
    """æ¸…ç† HTML æ ‡ç­¾"""
    if not text:
        return ""
    text = re.sub(r'<[^>]+>', '', text)
    return text.strip()


def fetch_rss(source: dict) -> list:
    """
    æŠ“å–å•ä¸ª RSS æº

    Args:
        source: åŒ…å« name å’Œ url çš„å­—å…¸

    Returns:
        æ–‡ç« åˆ—è¡¨
    """
    name = source["name"]
    url = source["url"]

    print(f"ğŸ“¡ æ­£åœ¨æŠ“å–: {name} ({url})...")

    try:
        # è·å– RSS Feed
        response = requests.get(url, timeout=REQUEST_TIMEOUT, allow_redirects=True)
        response.raise_for_status()

        # è§£æ RSS
        feed = feedparser.parse(response.content)

        articles = []
        for entry in feed.entries:
            # æå–æ ‡é¢˜
            title = entry.get("title", "")

            # æå–é“¾æ¥
            link = entry.get("link", "")

            # æå–æ‘˜è¦ (ä¼˜å…ˆç”¨ descriptionï¼Œå…¶æ¬¡ç”¨ summary)
            raw_summary = entry.get("description", "") or entry.get("summary", "")

            # æ¸…ç† HTML æ ‡ç­¾
            summary = clean_html(raw_summary)[:500]

            # ä½¿ç”¨é“¾æ¥ä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦
            external_id = link

            if title and link:
                articles.append({
                    "title": title,
                    "url": link,
                    "source": name,
                    "summary": summary,
                    "raw_summary": raw_summary,  # ä¿å­˜åŸå§‹æ‘˜è¦ä¾› AI å¤„ç†
                    "external_id": external_id
                })

        print(f"   âœ… æˆåŠŸè·å– {len(articles)} æ¡")
        return articles

    except requests.exceptions.Timeout:
        print(f"   â±ï¸  è¶…æ—¶: {url}")
        return []

    except requests.exceptions.RequestException as e:
        print(f"   âŒ ç½‘ç»œé”™è¯¯: {e}")
        return []

    except Exception as e:
        print(f"   âš ï¸  è§£æé”™è¯¯: {e}")
        return []


def process_articles_with_ai(articles: list) -> list:
    """
    ä½¿ç”¨ AI ä¼˜åŒ–æ–‡ç« æ‘˜è¦

    Args:
        articles: æ–‡ç« åˆ—è¡¨

    Returns:
        å¤„ç†åçš„æ–‡ç« åˆ—è¡¨
    """
    if not ENABLE_AI_SUMMARY:
        print("ğŸ“ AI æ‘˜å·²ç¦ç”¨ï¼Œä½¿ç”¨åŸå§‹æ‘˜è¦")
        return articles

    if not GROQ_API_KEY:
        print("âš ï¸  æœªè®¾ç½® GROQ_API_KEYï¼Œä½¿ç”¨åŸå§‹æ‘˜è¦")
        return articles

    print(f"ğŸ¤– æ­£åœ¨ä½¿ç”¨ AI ä¼˜åŒ– {len(articles)} æ¡æ‘˜è¦...")

    for i, article in enumerate(articles, 1):
        title = article["title"]
        raw_summary = article.get("raw_summary") or article["summary"]

        print(f"   [{i}/{len(articles)}] å¤„ç†: {title[:30]}...", end=" ")

        # è°ƒç”¨ AI ä¼˜åŒ–æ‘˜è¦
        ai_summary = summarize_with_ai(title, raw_summary)

        article["summary"] = ai_summary
        print("âœ“")

        # é¿å…è§¦å‘é€Ÿç‡é™åˆ¶
        if i < len(articles):
            time.sleep(1)

    return articles


def upload_articles(articles: list) -> bool:
    """
    å°†æ–‡ç« ä¸Šä¼ åˆ° Worker

    Args:
        articles: æ–‡ç« åˆ—è¡¨

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    if not articles:
        return True

    print(f"ğŸ“¤ æ­£åœ¨ä¸Šä¼  {len(articles)} æ¡æ–‡ç« åˆ° API...")

    try:
        response = requests.post(
            API_URL,
            headers={
                "x-api-key": API_KEY,
                "Content-Type": "application/json"
            },
            json=articles,
            timeout=60
        )

        response.raise_for_status()
        result = response.json()

        print(f"   âœ… ä¸Šä¼ æˆåŠŸ: æ–°å¢ {result.get('inserted', 0)} æ¡, è·³è¿‡ {result.get('skipped', 0)} æ¡")
        return True

    except requests.exceptions.HTTPError as e:
        print(f"   âŒ HTTP é”™è¯¯: {e}")
        if response.status_code == 401:
            print(f"   âš ï¸  API å¯†é’¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥ API_KEY é…ç½®")
        return False

    except requests.exceptions.RequestException as e:
        print(f"   âŒ ç½‘ç»œé”™è¯¯: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("   RSS æ–°é—»æŠ“å–è„šæœ¬ (AI å¢å¼ºç‰ˆ)")
    print("=" * 50)
    print()

    # æ£€æŸ¥é…ç½®
    if not API_URL or "YOUR_WORKER_URL" in API_URL:
        print("âŒ é”™è¯¯: è¯·å…ˆé…ç½® API_URL")
        sys.exit(1)

    if not API_KEY or "YOUR_API_KEY" in API_KEY:
        print("âŒ é”™è¯¯: è¯·å…ˆé…ç½® API_KEY")
        sys.exit(1)

    # æ˜¾ç¤º AI çŠ¶æ€
    if ENABLE_AI_SUMMARY and GROQ_API_KEY:
        print(f"ğŸ¤– AI æ‘˜è¦: å·²å¯ç”¨")
    else:
        print(f"ğŸ“ AI æ‘˜è¦: å·²ç¦ç”¨")

    print(f"API åœ°å€: {API_URL}")
    print(f"RSS æºæ•°é‡: {len(SOURCES)}")
    print()

    # æ”¶é›†æ‰€æœ‰æ–‡ç« 
    all_articles = []

    for i, source in enumerate(SOURCES, 1):
        print(f"[{i}/{len(SOURCES)}] ", end="")

        articles = fetch_rss(source)
        all_articles.extend(articles)

        # é¿å…è¯·æ±‚è¿‡å¿«
        if i < len(SOURCES):
            time.sleep(1)

    print()
    print(f"ğŸ“Š æ€»å…±æŠ“å–: {len(all_articles)} æ¡æ–‡ç« ")
    print()

    # AI å¤„ç†æ‘˜è¦
    if all_articles:
        all_articles = process_articles_with_ai(all_articles)
        print()

    # ä¸Šä¼ æ–‡ç« 
    if all_articles:
        success = upload_articles(all_articles)
        if success:
            print()
            print("ğŸ‰ å…¨éƒ¨å®Œæˆ!")
        else:
            print()
            print("âš ï¸  ä¸Šä¼ å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œå’Œé…ç½®")
            sys.exit(1)
    else:
        print("âš ï¸  æ²¡æœ‰æŠ“å–åˆ°ä»»ä½•æ–‡ç« ")


if __name__ == "__main__":
    main()
